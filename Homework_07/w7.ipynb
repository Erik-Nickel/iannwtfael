{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5724b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes\n",
    "# 1 check out this link to see how that’s done in a really easy way with the yield statement! \n",
    "# 2 You can just use a for loop iterating over num samples.\n",
    "# 3 You may want to make use of np.random.normal(size=).\n",
    "# 4 You can use np.sum(axis=) along the last axis and compare it to 0. Remember your output should be at best of type ’integer’ not ’boolean’\n",
    "# 5 Use np.expand dims(,-1) before you yield. The output shapes should be (seq len,1) and (1) for input and target respectiveley.\n",
    "# 6 For example, we chose 80.000.\n",
    "# 7 Shuffling, Batching.... As always.\n",
    "# 8 You can use a Dense layer for each gate with a hidden size specified by units and a sigmoid activation.\n",
    "# 9 To do so, check out the argument bias initializer= of the keras Dense layer impleme- nation and the tf.keras.initializers objects.\n",
    "# 10 For the concatenation of the input and the hidden state to pass on to the forget gate, you can make use of tf.concat( (), axis=).\n",
    "# 11 The appropiate size would be bacth size, cell units and you may want to use tf.zeros()\n",
    "# 12 Consider that you have a binary classification task. How many units should your readout layer haven and what activation function should you use?\n",
    "# 13 Do not forget to initialize the LSTM states with zeros each time you call your model and pass those on to your LSTM\n",
    "# 14 You may want to use slicing, -1 is always the last irrespective of the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b33927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1.1\n",
    "\n",
    "\n",
    "def integration_task(seq_len, num_samples):\n",
    "    # for num_samples times yield random signal of size seq_len\n",
    "    # and a target (sum of noise signal is > or < than 1)\n",
    "    target = 0\n",
    "    \n",
    "    for i in num_samples:\n",
    "        target = target + i\n",
    "        ran = np.random.normal(size=seq_len)\n",
    "\n",
    "        \n",
    "    if np.sum(axis=target) > 0:\n",
    "        tar_check = 1\n",
    "        ran = np.expand_dims(ran,-1)\n",
    "        yield ran, tar_check \n",
    "    else:\n",
    "        yield 1\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def my_integration_task():\n",
    "    \n",
    "    num_samples = 80000\n",
    "    seq_len = 25\n",
    "    \n",
    "    yield integration_task(seq_len, num_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5afda4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: split data into training and test data\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(my_integration_task, output_signature = tf.TensorSpec(shape=[10,1],dtype=tf.dtypes.float32))\n",
    "\n",
    "# training_data, testing_data = train_test_split(dataset, test_size=0.2, random_state=25)\n",
    "\n",
    "\n",
    "def prepare_data(ds):\n",
    "    return ds.shuffle(1000).batch(32).prefetch(20)\n",
    "                                         \n",
    "dataset = prepare_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8f7a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - The network\n",
    "\n",
    "class LSTM_Cell(): # hidden_state, cell_state\n",
    "    \n",
    "    def __init__(self, units, unit_forget_bias = False):\n",
    "        \n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        \n",
    "        self.dense1 = tf.keras.layers.Dense(units, kernel_regularizer=kernel_regularizer, use_bias=False, activation = tf.nn.sigmoid)\n",
    "        self.dense2 = tf.keras.layers.Dense(units, kernel_regularizer=kernel_regularizer, use_bias=False, activation = tf.nn.tanh)\n",
    "         \n",
    "        self.bias = tf.Variable(tf.zeros(units), name=\"LSTM_Cell_biases\")\n",
    "        \n",
    "        # for forget gate:\n",
    "        if unit_forget_bias == True:\n",
    "            bias +1\n",
    "            \n",
    "        weights = list()\n",
    "        \n",
    "        \n",
    "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='kernel')\n",
    "        \n",
    "        # point wise multiplication of layers:\n",
    "        # to_add_cell = np.dot(self.dense1, self.dense2)\n",
    "        \n",
    "        \n",
    "        return\n",
    "    \n",
    "    def call(self, x, states): # tf.concat( (), axis=)\n",
    "        \n",
    "        prev_output = states[0]\n",
    "                \n",
    "        to_output = np.dot(pre_output * self.dense1) +  self.bias\n",
    "            \n",
    "        # out = tf.nn.tanh(to_output)\n",
    "        \n",
    "        return to_output\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "class LSTM_Layer():\n",
    "    \n",
    "    def __init__(self, cell):\n",
    "        \n",
    "        cell = LSTM_Cell(32, False)\n",
    "    \n",
    "    \n",
    "    def call(self,x,states):\n",
    "        # input is shape [batch_size, seq_len, input_size]\n",
    "        # output is shape [batch_size, seq_len, output_size]\n",
    "        \n",
    "        for i in states:\n",
    "            \n",
    "        \n",
    "        output_size = states[0]\n",
    "        \n",
    "        to_out = [x[0], x[1], output_size]\n",
    "        \n",
    "        return \n",
    "    \n",
    "    def zero_states(self, batch_size):\n",
    "        \n",
    "        size = batch_size[0]\n",
    "        zero_state = np.zeros((size,),dtype='i,i')\n",
    "        \n",
    "        return zero_state\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class LSTM_Model():\n",
    "    \n",
    "    def __init__():\n",
    "        \n",
    "        # put into Layer?\n",
    "        read_in_layer = tf.keras.layers.Dense(128, activation = \"sigmoid\")\n",
    "        output_layer = tf.keras.layers.Dense(10, activation = \"tanh\")\n",
    "\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        out = self.read_in_layer(x)\n",
    "        out = self.output_layer(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e355c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
