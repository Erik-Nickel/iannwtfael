{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5724b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes\n",
    "# 1 check out this link to see how that’s done in a really easy way with the yield statement! \n",
    "# 2 You can just use a for loop iterating over num samples.\n",
    "# 3 You may want to make use of np.random.normal(size=).\n",
    "# 4 You can use np.sum(axis=) along the last axis and compare it to 0. Remember your output should be at best of type ’integer’ not ’boolean’\n",
    "# 5 Use np.expand dims(,-1) before you yield. The output shapes should be (seq len,1) and (1) for input and target respectiveley.\n",
    "# 6 For example, we chose 80.000.\n",
    "# 7 Shuffling, Batching.... As always.\n",
    "# 8 You can use a Dense layer for each gate with a hidden size specified by units and a sigmoid activation.\n",
    "# 9 To do so, check out the argument bias initializer= of the keras Dense layer impleme- nation and the tf.keras.initializers objects.\n",
    "# 10 For the concatenation of the input and the hidden state to pass on to the forget gate, you can make use of tf.concat( (), axis=).\n",
    "# 11 The appropiate size would be bacth size, cell units and you may want to use tf.zeros()12Consider that you have a binary classification task. How many units should your readout layer haven and what activation function should you use?13Do not forget to initialize the LSTM states with zeros each time you call your model and pass those on to your LSTM14You may want to use slicing, -1 is always the last irrespective of the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b33927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 1.1\n",
    "\n",
    "\n",
    "def integration_task(seq_len, num_samples):\n",
    "    # for num_samples times yield random signal of size seq_len\n",
    "    # and a target (sum of noise signal is > or < than 1)\n",
    "    target = 0\n",
    "    \n",
    "    for i in num_samples:\n",
    "        target = target + i\n",
    "        ran = np.random.normal(size=seq_len)\n",
    "        tar_check = np.sum(axis=ran)\n",
    "        # np.expand dims(,-1)\n",
    "        yield tar_check, ran \n",
    "    \n",
    "    \n",
    "def my_integration_task():\n",
    "    \n",
    "    num_samples = 80000\n",
    "    seq_len = 25\n",
    "    \n",
    "    yield integration_task(seq_len, num_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5afda4b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13899/2358375229.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_integration_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shape' is not defined"
     ]
    }
   ],
   "source": [
    "# ToDo: split data into training and test data\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(my_integration_task, output_signature = tf.TensorSpec(shape,dtype))\n",
    "\n",
    "def prepare_data(ds):\n",
    "    return ds.shuffle(1000).batch(32).prefetch(20)\n",
    "                                         \n",
    "dataset = prepare_ds(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8f7a265",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hidden_state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24184/2484002130.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 2 - The network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLSTM_Cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hidden_state' is not defined"
     ]
    }
   ],
   "source": [
    "# 2 - The network\n",
    "\n",
    "class LSTM_Cell(): # hidden_state, cell_state\n",
    "    \n",
    "    def __init__(self, units):\n",
    "        \n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        \n",
    "        weights = list()\n",
    "        weights = init\n",
    "        bias = 0\n",
    "        \n",
    "        # for forget gate:\n",
    "        if unit_forget_bias == True:\n",
    "            bias +1\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def call(self, x, states): # tf.concat( (), axis=)\n",
    "        \n",
    "        pre_output = states[0]\n",
    "        \n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "class LSTM_Layer():\n",
    "    \n",
    "    def __init__(self, cell):\n",
    "        \n",
    "        Cell1 = LSTM_Cell()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def call(self,x,states):\n",
    "        return\n",
    "    \n",
    "    def zero_states(self, batch_size):\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class LSTM_Model():\n",
    "    \n",
    "    def __init__():\n",
    "        \n",
    "        read_in_layer = 0 # placeholder\n",
    "        output_layer = 0 # placeholder\n",
    "        return\n",
    "    \n",
    "    def call(self, x):\n",
    "        return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
